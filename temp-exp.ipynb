{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokul\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from pandas.io.json import json_normalize as jsy\n",
    "#!pip install gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import brown # , #movie_review\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_set = pd.read_json('C:/Users/gokul/Documents/Projects/selqa-evaluater/SelQA-ass-dev.json', lines=True)\n",
    "train_set = pd.read_json('C:/Users/gokul/Documents/Projects/selqa-evaluater/SelQA-ass-train.json', lines = True)\n",
    "test_set = pd.read_json('C:/Users/gokul/Documents/Projects/selqa-evaluater/SelQA-ass-test.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>candidates</th>\n",
       "      <th>is_paraphrase</th>\n",
       "      <th>question</th>\n",
       "      <th>section</th>\n",
       "      <th>sentences</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table tennis</td>\n",
       "      <td>[4]</td>\n",
       "      <td>False</td>\n",
       "      <td>Does a 40mm table tennis ball spin more or les...</td>\n",
       "      <td>Ball</td>\n",
       "      <td>[The international rules specify that the game...</td>\n",
       "      <td>SPORT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blow Me (One Last Kiss)</td>\n",
       "      <td>[10]</td>\n",
       "      <td>False</td>\n",
       "      <td>What does Pink wear in the video?</td>\n",
       "      <td>Music video</td>\n",
       "      <td>[The music video for \"Blow Me (One Last Kiss)\"...</td>\n",
       "      <td>MUSIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chile</td>\n",
       "      <td>[16]</td>\n",
       "      <td>True</td>\n",
       "      <td>In what year was the Chilean National Museum o...</td>\n",
       "      <td>Tourism</td>\n",
       "      <td>[Tourism in Chile has experienced sustained gr...</td>\n",
       "      <td>COUNTRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Battle of Hastings</td>\n",
       "      <td>[6]</td>\n",
       "      <td>False</td>\n",
       "      <td>How many times was the who national \"fyrd\" cal...</td>\n",
       "      <td>English army and Harold's preparations</td>\n",
       "      <td>[The English army was organised along regional...</td>\n",
       "      <td>HISTORICAL EVENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Mindy Project</td>\n",
       "      <td>[6]</td>\n",
       "      <td>False</td>\n",
       "      <td>Who did Chris Messina play on The Mindy Project?</td>\n",
       "      <td>Production and development</td>\n",
       "      <td>[The series was initially commissioned by NBC,...</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   article candidates  is_paraphrase  \\\n",
       "0             Table tennis        [4]          False   \n",
       "1  Blow Me (One Last Kiss)       [10]          False   \n",
       "2                    Chile       [16]           True   \n",
       "3       Battle of Hastings        [6]          False   \n",
       "4        The Mindy Project        [6]          False   \n",
       "\n",
       "                                            question  \\\n",
       "0  Does a 40mm table tennis ball spin more or les...   \n",
       "1                  What does Pink wear in the video?   \n",
       "2  In what year was the Chilean National Museum o...   \n",
       "3  How many times was the who national \"fyrd\" cal...   \n",
       "4   Who did Chris Messina play on The Mindy Project?   \n",
       "\n",
       "                                  section  \\\n",
       "0                                    Ball   \n",
       "1                             Music video   \n",
       "2                                 Tourism   \n",
       "3  English army and Harold's preparations   \n",
       "4              Production and development   \n",
       "\n",
       "                                           sentences               type  \n",
       "0  [The international rules specify that the game...              SPORT  \n",
       "1  [The music video for \"Blow Me (One Last Kiss)\"...              MUSIC  \n",
       "2  [Tourism in Chile has experienced sustained gr...            COUNTRY  \n",
       "3  [The English army was organised along regional...  HISTORICAL EVENTS  \n",
       "4  [The series was initially commissioned by NBC,...                 TV  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### following is helper cell no need to run for exposure purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set[test_set['article']=='Table tennis']\n",
    "x = test_set.loc[1422]['sentences']\n",
    "train_set[(train_set['article']=='Table tennis')&(train_set['section']=='Ball')]\n",
    "\n",
    "temp = (train_set.loc[0]['sentences'])\n",
    "j=0\n",
    "for i in range(len((train_set.loc[0]['sentences']))):\n",
    "    print(j)\n",
    "    print(temp[i])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataframe from origine - mapping question to answer yet to complete for more than 1 candidate keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame(train_set['question'])\n",
    "train['answers'] = \"NA\"\n",
    "train.shape\n",
    "\n",
    "temp1 = len(train_set)\n",
    "for i in range(temp1):\n",
    "    #print(type(train_set.loc[i]['question']))\n",
    "    temp = len(train_set.loc[i]['candidates'])\n",
    "    if temp==1:\n",
    "        anskey = train_set.loc[i]['candidates'][0]\n",
    "        #print(type(train_set.loc[i]['sentences'][anskey]))\n",
    "        train.loc[i]['answers'] = train_set.loc[i]['sentences'][anskey]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writetrain = train[train['answers']!=\"NA\"]\n",
    "X_train = np.array(writetrain['question'])\n",
    "Y_train = np.array(writetrain['answers'])\n",
    "\n",
    "maxLenxt = len(min(X_train, key=len).split())\n",
    "maxLenyt = len(min(X_train, key=len).split())\n",
    "minLenxt = len(min(X_train, key=len).split())\n",
    "minLenyt = len(min(X_train, key=len).split())\n",
    "print(\"Max lenght \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_glove_vec(glove_file):\n",
    "    with open(glove_file,encoding='utf8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vec('C:/Users/gokul/Documents/Deep_learning/New folder/C5W2A2 - Emojify - v2/data/glove.6B.50d.txt')\n",
    "\n",
    "word = \"expired\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('care', 0.9206393361091614),\n",
       " ('job', 0.9165905714035034),\n",
       " ('trouble', 0.9065046310424805),\n",
       " ('work', 0.8878711462020874),\n",
       " ('getting', 0.8855317234992981)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b = Word2Vec(brown.sents())\n",
    "b.most_similar('money', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.util.ConcatenatedCorpusView"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = list(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'urged',\n",
       " 'that',\n",
       " 'the',\n",
       " 'city',\n",
       " '``',\n",
       " 'take',\n",
       " 'steps',\n",
       " 'to',\n",
       " 'remedy',\n",
       " \"''\",\n",
       " 'this',\n",
       " 'problem',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e590a12e9af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab_from_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab_from_freq\u001b[1;34m(self, word_freq, keep_raw_vocab, corpus_count, trim_rule, update)\u001b[0m\n\u001b[0;32m    524\u001b[0m         logger.info(\n\u001b[0;32m    525\u001b[0m             \u001b[1;34m\"collected %i different raw word, with total frequency of %i\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         )\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "b.build_vocab_from_freq(word_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
