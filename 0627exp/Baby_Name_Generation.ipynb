{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model for error row finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import generator_stop\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "from nltk.probability import *\n",
    "import string\n",
    "import copy\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# li = ['timestamp', 'description','limit6','mailid','float']\n",
    "# temp = pd.read_csv(\"./dataset.csv\")\n",
    "temp = pd.read_csv(\"./reld.csv\", delimiter='|', header=None, low_memory=False)\n",
    "temp.columns = temp.columns.astype(str)\n",
    "temp = temp.fillna(\"\")\n",
    "temp.to_csv(\"./input.csv\")\n",
    "tempn = pd.DataFrame()\n",
    "for i in temp.columns:\n",
    "    tempn[str(i)] = '*' + temp[str(i)].map(str) + '*'\n",
    "le80 = int(0.8 * len(tempn))\n",
    "npdf = copy.deepcopy(tempn[:le80])\n",
    "tedf = copy.deepcopy(tempn[le80:])\n",
    "\n",
    "\n",
    "\n",
    "def map_parameter_init():\n",
    "    d = {}\n",
    "    pun = list(string.punctuation)\n",
    "    num = list(string.digits)\n",
    "    let = list(string.ascii_letters)\n",
    "    for i in pun:\n",
    "        d[i] = i\n",
    "    for j in num:\n",
    "        d[j] = 'n'\n",
    "    for k in let:\n",
    "        d[k] = 'c'\n",
    "    d[' '] = ' '\n",
    "    d['\\n'] = '\\n'\n",
    "    d['\\t'] = '\\t'\n",
    "    return d\n",
    "\n",
    "d = map_parameter_init()\n",
    "vi = dict()\n",
    "cfd = dict()\n",
    "mingram = dict()\n",
    "total = dict()\n",
    "cols = temp.columns\n",
    "lin = {key:[] for key in cols}\n",
    "rejli = {key:[] for key in cols}\n",
    "rejrli ={key:[] for key in cols}\n",
    "rejpd = pd.DataFrame(columns=temp.columns, index = range(300)) #.reindex_like(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132185\n",
      "3063049\n",
      "9645875\n",
      "8683599\n",
      "2906211\n",
      "1837829\n",
      "1745034\n",
      "3554568\n",
      "1225219\n",
      "2940393\n",
      "7351319\n",
      "1621316\n",
      "1531524\n",
      "1531524\n",
      "2326402\n",
      "2261705\n",
      "{'0': <ConditionalFreqDist with 14 conditions>, '1': <ConditionalFreqDist with 10 conditions>, '2': <ConditionalFreqDist with 151 conditions>, '3': <ConditionalFreqDist with 164 conditions>, '4': <ConditionalFreqDist with 8 conditions>, '5': <ConditionalFreqDist with 6 conditions>, '6': <ConditionalFreqDist with 8 conditions>, '7': <ConditionalFreqDist with 84 conditions>, '8': <ConditionalFreqDist with 4 conditions>, '9': <ConditionalFreqDist with 26 conditions>, '10': <ConditionalFreqDist with 24 conditions>, '11': <ConditionalFreqDist with 30 conditions>, '12': <ConditionalFreqDist with 8 conditions>, '13': <ConditionalFreqDist with 9 conditions>, '14': <ConditionalFreqDist with 8 conditions>, '15': <ConditionalFreqDist with 115 conditions>}\n"
     ]
    }
   ],
   "source": [
    "def mapval(a, i):\n",
    "    global lin\n",
    "    u,inv = np.unique(a,return_inverse = True)\n",
    "    te = tuple(np.array([d[x] for x in u])[inv])\n",
    "    lin[str(i)].append(te)\n",
    "\n",
    "def trainmode():\n",
    "    for i in cols:\n",
    "        #distribution counting\n",
    "        tokd = pd.DataFrame(npdf[str(i)].map(str).apply(list))\n",
    "        val = tokd[str(i)].apply(mapval,args = (i,))\n",
    "        vi[str(i)] = collections.Counter(lin[str(i)])\n",
    "\n",
    "        ##Language model implementation\n",
    "        toke = list(npdf[str(i)].str.cat(sep='\\n'))\n",
    "        minv = npdf[str(i)].map(len).min()\n",
    "        mingram[str(i)] = minv\n",
    "        u,inv = np.unique(toke,return_inverse = True)\n",
    "        te = np.array([d[x] for x in u])[inv].reshape(len(toke))\n",
    "        total[str(i)] = len(te)\n",
    "        bigr = nltk.ngrams(te,mingram[str(i)])\n",
    "        condition_pairs = (((w[:-1]), w[-1]) for w in bigr)\n",
    "        cfd[str(i)] = nltk.ConditionalFreqDist(condition_pairs)\n",
    "        print(total[str(i)])\n",
    "    print(cfd)\n",
    "\n",
    "\n",
    "trainmode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd['0'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rejected items in 0 is 8 \n",
      "\n",
      "Number of rejected items in 1 is 0 \n",
      "\n",
      "Number of rejected items in 2 is 17746 \n",
      "\n",
      "Number of rejected items in 3 is 285 \n",
      "\n",
      "Number of rejected items in 4 is 0 \n",
      "\n",
      "Number of rejected items in 5 is 0 \n",
      "\n",
      "Number of rejected items in 6 is 0 \n",
      "\n",
      "Number of rejected items in 7 is 474 \n",
      "\n",
      "Number of rejected items in 8 is 0 \n",
      "\n",
      "Number of rejected items in 9 is 0 \n",
      "\n",
      "Number of rejected items in 10 is 0 \n",
      "\n",
      "Number of rejected items in 11 is 59 \n",
      "\n",
      "Number of rejected items in 12 is 0 \n",
      "\n",
      "Number of rejected items in 13 is 0 \n",
      "\n",
      "Number of rejected items in 14 is 0 \n",
      "\n",
      "Number of rejected items in 15 is 101 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run on actual data\n",
    "def tmapval(a, va,i):\n",
    "    u,inv = np.unique(a,return_inverse = True)\n",
    "    te = tuple(np.array([d[x] for x in u])[inv])\n",
    "    try:\n",
    "        tel = vi[str(i)].get(te)/va\n",
    "    except:\n",
    "        rejli[str(i)].append(te)\n",
    "        rejrli[str(i)].append(a)\n",
    "        \n",
    "def feature_mapping():\n",
    "    count = 0\n",
    "    for i in cols:\n",
    "        ind = 0\n",
    "        tdf = pd.DataFrame(tedf[str(i)].map(str).apply(list))\n",
    "        count = len(tdf.index)\n",
    "        tempa = tdf[str(i)].apply(tmapval, args = (count,i))\n",
    "        print(\"Number of rejected items in\",str(i),\"is\", len(rejli[str(i)]),\"\\n\")\n",
    "        if rejli[str(i)] !=[]:\n",
    "            for j in rejli[str(i)]:\n",
    "                tr = nltk.ngrams(j,mingram[str(i)])\n",
    "                if list(tr) == []:\n",
    "                    vi = 0\n",
    "                    tem = copy.deepcopy(rejrli[str(i)][rejli[str(i)].index(j)])\n",
    "                    tem.pop(0)\n",
    "                    tem.pop(-1)\n",
    "                    rejpd.at[ind, str(i)] = str(\"\".join(tem))\n",
    "                    ind+=1\n",
    "                    continue\n",
    "                else:\n",
    "                    tr = nltk.ngrams(j,mingram[str(i)])\n",
    "                    cpairs = (((w[:-1]), w[-1]) for w in tr)\n",
    "                    co = 0\n",
    "                    vi = 0\n",
    "                    for k in list(cpairs):\n",
    "                        v = cfd[str(i)][k[0]][k[1]]\n",
    "                        if co == 0:\n",
    "                            vi = v/total[str(i)]\n",
    "                            co = 1\n",
    "                        else:\n",
    "                            vi *= v/total[str(i)]\n",
    "                    if vi ==0:\n",
    "                        tel = copy.deepcopy(rejrli[str(i)][rejli[str(i)].index(j)])\n",
    "                        tel.pop(0)\n",
    "                        tel.pop(-1)\n",
    "                        rejpd.at[ind, str(i)] = str(\"\".join(tel))\n",
    "                        ind+=1\n",
    "                    elif vi!=0:\n",
    "                        pass\n",
    "#                         print(\"Accepted after language mode:\",\"\".join(rejrli[str(i)][rejli[str(i)].index(j)]))\n",
    "                \n",
    "x = feature_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejpd.to_csv(\"./output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_pairs.throw()\n",
    "# a = {}\n",
    "# k = 0\n",
    "# while k < 10:\n",
    "#     <dynamically create key> \n",
    "#     key = ...\n",
    "#     <calculate value> \n",
    "#     value = ...\n",
    "#     a[key] = value \n",
    "#     k += 1\n",
    "\n",
    "# t = nltk.ngrams(\"timestamp,description,ipaddress,limit6,float,year,money,country,Enum,mailid,bool,longnumber,stockprice,output\", 3)\n",
    "# # list(t)\n",
    "# for i in list(t):\n",
    "#     print(i)\n",
    "#     print(i[:-1])\n",
    "#     print(i[-1])\n",
    "    \n",
    "# t = nltk.ngrams(\"timestamp,description,ipalongnumber,stockprice,output\", 3)\n",
    "# if list(t) == []:\n",
    "#     print(\"in\")\n",
    "# else:\n",
    "#     print(\"out\")\n",
    "\n",
    "    \n",
    "# # collections.Counter(vi.most_common(1))\n",
    "# l = list(vi.keys())\n",
    "# for i in l:\n",
    "#     print(collections.Counter(i))\n",
    "# npdf['mailid'].map(len).sum()/len(npdf['mailid'].index) $%average length of list in a columnx\n",
    "# fdist = nltk.FreqDist(w.lower() for w in te)\n",
    "# total = 0\n",
    "# for word in fdist:\n",
    "#     total += fdist[word]\n",
    "    \n",
    "# v = list('**nncn')\n",
    "# for w in v:\n",
    "#     if w in fdist:\n",
    "#         print(w,'freq',fdist[w],'prob',fdist[w]/total)\n",
    "#     else:\n",
    "#         print(w,'freq',0,'prob',0)\n",
    "# cfd.items()\n",
    "# cfd.keys()\n",
    "# cfd[v[0]][v[1]]\n",
    "\n",
    "# toke = list(data)\n",
    "# u,inv = np.unique(toke,return_inverse = True)\n",
    "# te = np.array([d[x] for x in u])[inv].reshape(len(toke))\n",
    "# esBigrams = ngrams(te, 3)\n",
    "# # list(esBigrams)[:10]\n",
    "# esBigramFreq = collections.Counter(esBigrams)\n",
    "# esBigramFreq.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
